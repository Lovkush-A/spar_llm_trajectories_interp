{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import circuitsvis as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from taker import Model\n",
    "from taker.hooks import HookConfig\n",
    "import csv\n",
    "import json\n",
    "from datetime import datetime\n",
    "from os import listdir\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../promptsV1.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    readdata = list(reader)\n",
    "    readdata = readdata[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_new_tokens = 200\n",
    "temperature = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df = pd.read_json(f\"../gemma9b_results/latest_orig_generation_new.jsonl\", lines=True)\n",
    "def split_at_double_newline(text):\n",
    "    # Ensure we are only working with strings longer than 15 characters\n",
    "    if len(text) > 15:\n",
    "        # Search for the first double newline after the 15th character\n",
    "        pos = text.find('\\n\\n', 15)\n",
    "        if pos != -1:  # Check if double newline was found\n",
    "            return text[:pos+2], text[pos:]  # Split and remove the newline from the second part\n",
    "    return text, text  # If no split is required, return the original text and None\n",
    "\n",
    "orig_df['paragraph1'], orig_df['paragraph2'] = zip(*orig_df['output'].apply(split_at_double_newline))\n",
    "orig_df['paragraph1'] = orig_df['prompt'].astype(str) + orig_df['paragraph1'].astype(str)\n",
    "print(repr(orig_df['paragraph1'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idlist = get_ids(orig_df['paragraph1'][0]).squeeze().tolist()\n",
    "# tokens = tokenizer.convert_ids_to_tokens(idlist)\n",
    "# print(tokens)\n",
    "def get_last_segment(text):\n",
    "    segments = text.split('\\n\\n')\n",
    "    return segments[-1].strip() if segments else ''\n",
    "\n",
    "generated_outputs = []\n",
    "for i, prompt in enumerate(orig_df['paragraph1'][:1]):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'].squeeze().tolist())\n",
    "    input_length = len(tokens)\n",
    "    custom_attention_mask = torch.zeros(input_length,input_length)\n",
    "    custom_attention_mask[0:tokens.index('\\n\\n'),0:tokens.index('\\n\\n')] = 1\n",
    "    custom_attention_mask[len(tokens)-1,len(tokens)-1] = 1\n",
    "    inputs['attention_mask'] = custom_attention_mask.unsqueeze(0)\n",
    "    print(inputs['attention_mask'].shape)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = m.generate(**inputs, max_new_tokens=150, temperature=temperature, do_sample=True)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(generated_text)\n",
    "    generated_outputs.append(get_last_segment(generated_text))\n",
    "\n",
    "generated_df = pd.DataFrame({'generated_output': generated_outputs})\n",
    "print(generated_df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
