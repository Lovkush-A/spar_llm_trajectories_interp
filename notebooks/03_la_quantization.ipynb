{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "from os import listdir\n",
    "\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_jsonl_file(data: list[dict], file: str) -> None:\n",
    "    with open(file, \"w\") as f:\n",
    "        for item in data:\n",
    "            json_line = json.dumps(item)\n",
    "            f.write(json_line + \"\\n\")\n",
    "\n",
    "\n",
    "def load_jsonl_file(file: str) -> list[dict]:\n",
    "    data = []\n",
    "    with open(file, \"r\") as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "# Quantization configuration\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "# Load the model with quantization\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi3_template = \"\"\"\n",
    "<|system|>\n",
    "You are a helpful assistant.<|end|>\n",
    "<|user|>\n",
    "{prompt}<|end|>\n",
    "<|assistant|>\n",
    "{start}\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "Write a short blog post about a recipe and the inspiration behind it.\n",
    " Do not include a title.\n",
    " Only reveal the dish after the story.\n",
    " Start with short story and then move to the recipe.\n",
    " To re-iterate, do not include a title.\n",
    "\"\"\".replace(\n",
    "    \"\\n\", \"\"\n",
    ")\n",
    "\n",
    "start = \"\"\"\n",
    "\" Once upon a time, in a quaint little village nestled between rolling hills and verdant fields,\n",
    " there lived an elderly woman named Agnes. Agnes was known for her warm smile and her legendary\n",
    " Sunday dinners that brought the entire neighborhood together. Her recipes were family heirlooms,\n",
    " passed down through generations, with each family adding their own touch to the final dish.\n",
    "<br><br>\n",
    "One crisp autumn evening, Agnes was reminiscing about her childhood, and how her grandmother used\n",
    " to gather everyone around the dinner table, sharing stories and laughter. These were the moments\n",
    " that shaped her, the memories that she passed on to her own children and grandchildren.\n",
    "<br><br>\n",
    "Inspired by her grandmother's legacy, Agnes decided to create a new dish that would encapsulate\n",
    " the essence of those cherished gatherings. She wanted something that was comforting and nourishing,\n",
    " a dish that could be prepared with love and shared with others. After days of experimentation, she\n",
    " finally created a recipe that she believed truly captured the spirit of her family's Sunday dinners.\n",
    "<br><br>\n",
    "**Agnes's\n",
    "\"\"\".replace(\n",
    "    \"\\n\", \"\"\n",
    ").replace(\n",
    "    \"<br>\", \"\\n\"\n",
    ")\n",
    "\n",
    "# start = \"\"\n",
    "\n",
    "text = phi3_template.format(\n",
    "    prompt=prompt,\n",
    "    start=start,\n",
    ")\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "temperature = 0.2\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 200,\n",
    "    \"return_full_text\": False,\n",
    "    \"temperature\": temperature,\n",
    "    \"do_sample\": True,\n",
    "}\n",
    "\n",
    "output = generator(text, **generation_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0.5\n",
    "max_new_tokens = 200\n",
    "generator = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "for temperature in [0.2, 0.4, 0.6, 0.8, 1.0]:\n",
    "    generation_args = {\n",
    "        \"max_new_tokens\": max_new_tokens,\n",
    "        \"return_full_text\": False,\n",
    "        \"temperature\": temperature,\n",
    "        \"do_sample\": True,\n",
    "    }\n",
    "    for _ in range(20):\n",
    "        output = generator(text, **generation_args)\n",
    "\n",
    "        # export output to json file, also tracking choices made\n",
    "        current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "        path_to_export = f\"../results/{current_time}_agnes_story.json\"\n",
    "\n",
    "        # Create a dictionary with the data to be written to the JSON file\n",
    "        data = {\n",
    "            \"model\": model_id,\n",
    "            \"temperature\": temperature,\n",
    "            \"max_new_tokens\": max_new_tokens,\n",
    "            \"prompt\": prompt,\n",
    "            \"start\": start,\n",
    "            \"output\": output[0][\"generated_text\"],\n",
    "        }\n",
    "\n",
    "        # Open the file in write mode and write the data as JSON\n",
    "        with open(path_to_export, \"w\") as file:\n",
    "            json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results from JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load results from json files\n",
    "files = listdir(\"../results\")\n",
    "\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../results/2024-07-13_18-04-11_agnes_story.jsonl\"\n",
    "results_df = pd.read_json(filepath, lines=True)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through rows and print temperature and output\n",
    "\n",
    "for _, row in results_df.iterrows():\n",
    "    print(f\"Temperature: {row['temperature']}\")\n",
    "    print(row[\"output\"].replace(\"\\n\", \"\")[:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = model.encode(results_df[\"output\"].to_list())\n",
    "print(embeddings.shape)\n",
    "\n",
    "# # Calculate the embedding similarities\n",
    "# similarities = model.similarity(embeddings, embeddings)\n",
    "# print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\"embeddings\"] = embeddings.tolist()\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carry out pca on embeddings using sklearn\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(embeddings)\n",
    "print(pca_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the embeddings using plotly\n",
    "import plotly.express as px\n",
    "\n",
    "results_df[\"pca1\"] = pca_result[:, 0]\n",
    "results_df[\"pca2\"] = pca_result[:, 1]\n",
    "\n",
    "fig = px.scatter(\n",
    "    results_df,\n",
    "    x=\"pca1\",\n",
    "    y=\"pca2\",\n",
    "    hover_data={\"pca1\": False, \"pca2\": False},\n",
    "    title=\"PCA of Agnes Story Embeddings\",\n",
    "    color=\"temperature\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
