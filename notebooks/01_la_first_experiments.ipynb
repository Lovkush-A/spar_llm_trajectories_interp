{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_lens.utils as utils\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.loading_from_pretrained import OFFICIAL_MODEL_NAMES\n",
    "\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = utils.get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt2',\n",
       " 'gpt2-medium',\n",
       " 'gpt2-large',\n",
       " 'gpt2-xl',\n",
       " 'distilgpt2',\n",
       " 'facebook/opt-125m',\n",
       " 'facebook/opt-1.3b',\n",
       " 'facebook/opt-2.7b',\n",
       " 'facebook/opt-6.7b',\n",
       " 'facebook/opt-13b',\n",
       " 'facebook/opt-30b',\n",
       " 'facebook/opt-66b',\n",
       " 'EleutherAI/gpt-neo-125M',\n",
       " 'EleutherAI/gpt-neo-1.3B',\n",
       " 'EleutherAI/gpt-neo-2.7B',\n",
       " 'EleutherAI/gpt-j-6B',\n",
       " 'EleutherAI/gpt-neox-20b',\n",
       " 'stanford-crfm/alias-gpt2-small-x21',\n",
       " 'stanford-crfm/battlestar-gpt2-small-x49',\n",
       " 'stanford-crfm/caprica-gpt2-small-x81',\n",
       " 'stanford-crfm/darkmatter-gpt2-small-x343',\n",
       " 'stanford-crfm/expanse-gpt2-small-x777',\n",
       " 'stanford-crfm/arwen-gpt2-medium-x21',\n",
       " 'stanford-crfm/beren-gpt2-medium-x49',\n",
       " 'stanford-crfm/celebrimbor-gpt2-medium-x81',\n",
       " 'stanford-crfm/durin-gpt2-medium-x343',\n",
       " 'stanford-crfm/eowyn-gpt2-medium-x777',\n",
       " 'EleutherAI/pythia-14m',\n",
       " 'EleutherAI/pythia-31m',\n",
       " 'EleutherAI/pythia-70m',\n",
       " 'EleutherAI/pythia-160m',\n",
       " 'EleutherAI/pythia-410m',\n",
       " 'EleutherAI/pythia-1b',\n",
       " 'EleutherAI/pythia-1.4b',\n",
       " 'EleutherAI/pythia-2.8b',\n",
       " 'EleutherAI/pythia-6.9b',\n",
       " 'EleutherAI/pythia-12b',\n",
       " 'EleutherAI/pythia-70m-deduped',\n",
       " 'EleutherAI/pythia-160m-deduped',\n",
       " 'EleutherAI/pythia-410m-deduped',\n",
       " 'EleutherAI/pythia-1b-deduped',\n",
       " 'EleutherAI/pythia-1.4b-deduped',\n",
       " 'EleutherAI/pythia-2.8b-deduped',\n",
       " 'EleutherAI/pythia-6.9b-deduped',\n",
       " 'EleutherAI/pythia-12b-deduped',\n",
       " 'EleutherAI/pythia-70m-v0',\n",
       " 'EleutherAI/pythia-160m-v0',\n",
       " 'EleutherAI/pythia-410m-v0',\n",
       " 'EleutherAI/pythia-1b-v0',\n",
       " 'EleutherAI/pythia-1.4b-v0',\n",
       " 'EleutherAI/pythia-2.8b-v0',\n",
       " 'EleutherAI/pythia-6.9b-v0',\n",
       " 'EleutherAI/pythia-12b-v0',\n",
       " 'EleutherAI/pythia-70m-deduped-v0',\n",
       " 'EleutherAI/pythia-160m-deduped-v0',\n",
       " 'EleutherAI/pythia-410m-deduped-v0',\n",
       " 'EleutherAI/pythia-1b-deduped-v0',\n",
       " 'EleutherAI/pythia-1.4b-deduped-v0',\n",
       " 'EleutherAI/pythia-2.8b-deduped-v0',\n",
       " 'EleutherAI/pythia-6.9b-deduped-v0',\n",
       " 'EleutherAI/pythia-12b-deduped-v0',\n",
       " 'EleutherAI/pythia-160m-seed1',\n",
       " 'EleutherAI/pythia-160m-seed2',\n",
       " 'EleutherAI/pythia-160m-seed3',\n",
       " 'NeelNanda/SoLU_1L_v9_old',\n",
       " 'NeelNanda/SoLU_2L_v10_old',\n",
       " 'NeelNanda/SoLU_4L_v11_old',\n",
       " 'NeelNanda/SoLU_6L_v13_old',\n",
       " 'NeelNanda/SoLU_8L_v21_old',\n",
       " 'NeelNanda/SoLU_10L_v22_old',\n",
       " 'NeelNanda/SoLU_12L_v23_old',\n",
       " 'NeelNanda/SoLU_1L512W_C4_Code',\n",
       " 'NeelNanda/SoLU_2L512W_C4_Code',\n",
       " 'NeelNanda/SoLU_3L512W_C4_Code',\n",
       " 'NeelNanda/SoLU_4L512W_C4_Code',\n",
       " 'NeelNanda/SoLU_6L768W_C4_Code',\n",
       " 'NeelNanda/SoLU_8L1024W_C4_Code',\n",
       " 'NeelNanda/SoLU_10L1280W_C4_Code',\n",
       " 'NeelNanda/SoLU_12L1536W_C4_Code',\n",
       " 'NeelNanda/GELU_1L512W_C4_Code',\n",
       " 'NeelNanda/GELU_2L512W_C4_Code',\n",
       " 'NeelNanda/GELU_3L512W_C4_Code',\n",
       " 'NeelNanda/GELU_4L512W_C4_Code',\n",
       " 'NeelNanda/Attn_Only_1L512W_C4_Code',\n",
       " 'NeelNanda/Attn_Only_2L512W_C4_Code',\n",
       " 'NeelNanda/Attn_Only_3L512W_C4_Code',\n",
       " 'NeelNanda/Attn_Only_4L512W_C4_Code',\n",
       " 'NeelNanda/Attn-Only-2L512W-Shortformer-6B-big-lr',\n",
       " 'NeelNanda/SoLU_1L512W_Wiki_Finetune',\n",
       " 'NeelNanda/SoLU_4L512W_Wiki_Finetune',\n",
       " 'ArthurConmy/redwood_attn_2l',\n",
       " 'llama-7b-hf',\n",
       " 'llama-13b-hf',\n",
       " 'llama-30b-hf',\n",
       " 'llama-65b-hf',\n",
       " 'meta-llama/Llama-2-7b-hf',\n",
       " 'meta-llama/Llama-2-7b-chat-hf',\n",
       " 'meta-llama/Llama-2-13b-hf',\n",
       " 'meta-llama/Llama-2-13b-chat-hf',\n",
       " 'meta-llama/Llama-2-70b-chat-hf',\n",
       " 'CodeLlama-7b-hf',\n",
       " 'CodeLlama-7b-Python-hf',\n",
       " 'CodeLlama-7b-Instruct-hf',\n",
       " 'meta-llama/Meta-Llama-3-8B',\n",
       " 'meta-llama/Meta-Llama-3-8B-Instruct',\n",
       " 'meta-llama/Meta-Llama-3-70B',\n",
       " 'meta-llama/Meta-Llama-3-70B-Instruct',\n",
       " 'Baidicoot/Othello-GPT-Transformer-Lens',\n",
       " 'bert-base-cased',\n",
       " 'roneneldan/TinyStories-1M',\n",
       " 'roneneldan/TinyStories-3M',\n",
       " 'roneneldan/TinyStories-8M',\n",
       " 'roneneldan/TinyStories-28M',\n",
       " 'roneneldan/TinyStories-33M',\n",
       " 'roneneldan/TinyStories-Instruct-1M',\n",
       " 'roneneldan/TinyStories-Instruct-3M',\n",
       " 'roneneldan/TinyStories-Instruct-8M',\n",
       " 'roneneldan/TinyStories-Instruct-28M',\n",
       " 'roneneldan/TinyStories-Instruct-33M',\n",
       " 'roneneldan/TinyStories-1Layer-21M',\n",
       " 'roneneldan/TinyStories-2Layers-33M',\n",
       " 'roneneldan/TinyStories-Instuct-1Layer-21M',\n",
       " 'roneneldan/TinyStories-Instruct-2Layers-33M',\n",
       " 'stabilityai/stablelm-base-alpha-3b',\n",
       " 'stabilityai/stablelm-base-alpha-7b',\n",
       " 'stabilityai/stablelm-tuned-alpha-3b',\n",
       " 'stabilityai/stablelm-tuned-alpha-7b',\n",
       " 'mistralai/Mistral-7B-v0.1',\n",
       " 'mistralai/Mistral-7B-Instruct-v0.1',\n",
       " 'mistralai/Mixtral-8x7B-v0.1',\n",
       " 'mistralai/Mixtral-8x7B-Instruct-v0.1',\n",
       " 'bigscience/bloom-560m',\n",
       " 'bigscience/bloom-1b1',\n",
       " 'bigscience/bloom-1b7',\n",
       " 'bigscience/bloom-3b',\n",
       " 'bigscience/bloom-7b1',\n",
       " 'bigcode/santacoder',\n",
       " 'Qwen/Qwen-1_8B',\n",
       " 'Qwen/Qwen-7B',\n",
       " 'Qwen/Qwen-14B',\n",
       " 'Qwen/Qwen-1_8B-Chat',\n",
       " 'Qwen/Qwen-7B-Chat',\n",
       " 'Qwen/Qwen-14B-Chat',\n",
       " 'Qwen/Qwen1.5-0.5B',\n",
       " 'Qwen/Qwen1.5-0.5B-Chat',\n",
       " 'Qwen/Qwen1.5-1.8B',\n",
       " 'Qwen/Qwen1.5-1.8B-Chat',\n",
       " 'Qwen/Qwen1.5-4B',\n",
       " 'Qwen/Qwen1.5-4B-Chat',\n",
       " 'Qwen/Qwen1.5-7B',\n",
       " 'Qwen/Qwen1.5-7B-Chat',\n",
       " 'Qwen/Qwen1.5-14B',\n",
       " 'Qwen/Qwen1.5-14B-Chat',\n",
       " 'microsoft/phi-1',\n",
       " 'microsoft/phi-1_5',\n",
       " 'microsoft/phi-2',\n",
       " 'microsoft/Phi-3-mini-4k-instruct',\n",
       " 'google/gemma-2b',\n",
       " 'google/gemma-7b',\n",
       " 'google/gemma-2b-it',\n",
       " 'google/gemma-7b-it',\n",
       " '01-ai/Yi-6B',\n",
       " '01-ai/Yi-34B',\n",
       " '01-ai/Yi-6B-Chat',\n",
       " '01-ai/Yi-34B-Chat',\n",
       " 'google-t5/t5-small',\n",
       " 'google-t5/t5-base',\n",
       " 'google-t5/t5-large',\n",
       " 'ai-forever/mGPT']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OFFICIAL_MODEL_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading model microsoft/Phi-3-mini-4k-instruct requires setting trust_remote_code=True\n",
      "/workspace/SPAR/interp-la/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "WARNING:root:Loading model microsoft/Phi-3-mini-4k-instruct state dict requires setting trust_remote_code=True\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.c1358f8a35e6d2af81890deffbbfa575b978c62f.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.c1358f8a35e6d2af81890deffbbfa575b978c62f.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "869849614d1146d19842777e07caa55d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model microsoft/Phi-3-mini-4k-instruct into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "# model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# model_name = \"gpt2-large\"\n",
    "\n",
    "model = HookedTransformer.from_pretrained(model_name=model_name, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a short blog post about a recipe and the inspiration behind it. Do not include a title. Only reveal the dish after the story. Start with a one, two or three paragraph story and then move to the recipe. To re-iterate, do not include a title.\n",
      "\n",
      "The recipe I’m sharing today is an amalgamation of my grandmother's traditional Italian pasta dish and my recent trip to Italy. \n",
      "\n",
      "My grandmother, Nonna Maria, always made the most delicious pasta. We would gather around the table, eagerly awaiting the rich aroma that filled our kitchen every time she prepared her signature dish. The scent would always linger in the air, as if it was a promise of the warmth and love that accompanied each bite. \n",
      "\n",
      "When I travelled to Italy, I was determined to recreate the dish to the best of my abilities. I spent hours exploring the bustling markets, indulging in the local cuisine, and soaking up the vibrant culture. Every meal was an experience, and I was eager to incorporate the flavors and techniques I learned into my recipe.\n",
      "\n",
      "After returning home, I sat down to deconstruct the dish and rebuild it in my kitchen. I started with the pasta, carefully selecting the perfect type of wheat and rolling it out to the perfect thickness. The sauce was a blend of traditional Italian ingredients, infused with my unique twist. The result was a dish that not only brought back cherished memories but also embodied the spirit of my journey through Italy.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Write a short blog post about a recipe and the inspiration behind it.\n",
    " Do not include a title.\n",
    " Only reveal the dish after the story.\n",
    " Start with a one, two or three paragraph story and then move to the recipe.\n",
    " To re-iterate, do not include a title.\n",
    "\"\"\".replace(\n",
    "    \"\\n\", \"\"\n",
    ")\n",
    "\n",
    "start = \"\"\"\n",
    "The recipe I’m sharing today is an amalgamation of my grandmother's traditional Italian pasta dish and my\n",
    "zzzrecent trip to Italy. \n",
    "\n",
    "My grandmother, Nonna Maria, always made the most delicious pasta. We would gather around the table,\n",
    "zzzeagerly awaiting the rich aroma that filled our kitchen every time she prepared her signature dish.\n",
    "zzzThe scent would always linger in the air, as if it was a promise of the warmth and love that accompanied\n",
    "zzzeach bite. \n",
    "\n",
    "When I travelled to Italy, I was determined to recreate the dish to the best of my abilities. I spent hours\n",
    "zzzexploring the bustling markets, indulging in the local cuisine, and soaking up the vibrant culture.\n",
    "zzzEvery meal was an experience, and I was eager to incorporate the flavors and techniques I learned into\n",
    "zzzmy recipe.\n",
    "\n",
    "After returning home, I sat down to deconstruct the dish and rebuild it in my kitchen. I started with\n",
    "zzzthe pasta, carefully selecting the perfect type of wheat and rolling it out to the perfect thickness.\n",
    "zzzThe sauce was a blend of traditional Italian ingredients, infused with my unique twist. The result was\n",
    "zzza dish that not only brought back cherished memories but also embodied the spirit of my journey through\n",
    "zzzItaly.\n",
    "\n",
    "\"\"\".replace(\n",
    "    \"\\nzzz\", \" \"\n",
    ")\n",
    "\n",
    "print(prompt)\n",
    "print(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6376781aaa034abd91590ba477b5c36b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 36.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m temperature \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.7\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprepend_bos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# export output to json file, also tracking choices made\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     current_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/workspace/SPAR/interp-la/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/SPAR/interp-la/.venv/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py:2095\u001b[0m, in \u001b[0;36mHookedTransformer.generate\u001b[0;34m(self, input, max_new_tokens, stop_at_eos, eos_token_id, do_sample, top_k, top_p, temperature, freq_penalty, use_past_kv_cache, prepend_bos, padding_side, return_type, verbose)\u001b[0m\n\u001b[1;32m   2092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_past_kv_cache:\n\u001b[1;32m   2093\u001b[0m     \u001b[38;5;66;03m# We just take the final tokens, as a [batch, 1] tensor\u001b[39;00m\n\u001b[1;32m   2094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2095\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2096\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2097\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogits\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2098\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprepend_bos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_bos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2099\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2100\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2101\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2102\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2103\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\n\u001b[1;32m   2104\u001b[0m             tokens,\n\u001b[1;32m   2105\u001b[0m             return_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2108\u001b[0m             past_kv_cache\u001b[38;5;241m=\u001b[39mpast_kv_cache,\n\u001b[1;32m   2109\u001b[0m         )\n",
      "File \u001b[0;32m/workspace/SPAR/interp-la/.venv/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py:549\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    545\u001b[0m         shortformer_pos_embed \u001b[38;5;241m=\u001b[39m shortformer_pos_embed\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    546\u001b[0m             devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[1;32m    547\u001b[0m         )\n\u001b[0;32m--> 549\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# block\u001b[39;49;00m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "File \u001b[0;32m/workspace/SPAR/interp-la/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/SPAR/interp-la/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/SPAR/interp-la/.venv/lib/python3.10/site-packages/transformer_lens/components/transformer_block.py:150\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m    143\u001b[0m     key_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m    144\u001b[0m     value_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m    146\u001b[0m attn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_attn_out(\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;66;03m# hook the residual stream states that are used to calculate the\u001b[39;00m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;66;03m# queries, keys and values, independently.\u001b[39;00m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mattn_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mparallel_attn_mlp:\n\u001b[1;32m    161\u001b[0m     resid_mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_resid_mid(resid_pre \u001b[38;5;241m+\u001b[39m attn_out)  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/SPAR/interp-la/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/SPAR/interp-la/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/SPAR/interp-la/.venv/lib/python3.10/site-packages/transformer_lens/components/abstract_attention.py:272\u001b[0m, in \u001b[0;36mAbstractAttention.forward\u001b[0;34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, attention_mask, position_bias)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_O\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m         out \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    271\u001b[0m             (\n\u001b[0;32m--> 272\u001b[0m                 \u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch pos head_index d_head, \u001b[39;49m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;43m                        head_index d_head d_model -> \u001b[39;49m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;43m                        batch pos d_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_O\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m             )\n\u001b[1;32m    280\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_O\n\u001b[1;32m    281\u001b[0m         )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# Explicitly calculate the attention result so it can be accessed by a hook\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;66;03m# This is off by default because it can easily eat through your GPU memory.\u001b[39;00m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mload_in_4bit:\n",
      "File \u001b[0;32m/workspace/SPAR/interp-la/.venv/lib/python3.10/site-packages/fancy_einsum/__init__.py:136\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(equation, *operands)\u001b[0m\n\u001b[1;32m    134\u001b[0m backend \u001b[38;5;241m=\u001b[39m get_backend(operands[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    135\u001b[0m new_equation \u001b[38;5;241m=\u001b[39m convert_equation(equation)\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_equation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/SPAR/interp-la/.venv/lib/python3.10/site-packages/fancy_einsum/__init__.py:54\u001b[0m, in \u001b[0;36mTorchBackend.einsum\u001b[0;34m(self, equation, *operands)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meinsum\u001b[39m(\u001b[38;5;28mself\u001b[39m, equation, \u001b[38;5;241m*\u001b[39moperands):\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/SPAR/interp-la/.venv/lib/python3.10/site-packages/torch/functional.py:385\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    387\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 36.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "temperature = 0.7\n",
    "\n",
    "for _ in range(1):\n",
    "    output = model.generate(\n",
    "        input=prompt + \"\\n\\n\" + start,\n",
    "        max_new_tokens=300,\n",
    "        temperature=temperature,\n",
    "        prepend_bos=False,\n",
    "    )\n",
    "\n",
    "    # export output to json file, also tracking choices made\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "    path_to_export = f\"../results/{current_time}.json\"\n",
    "\n",
    "    # Create a dictionary with the data to be written to the JSON file\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"temperature\": temperature,\n",
    "        \"prompt\": prompt,\n",
    "        \"start\": start,\n",
    "        \"output\": output,\n",
    "    }\n",
    "\n",
    "    # Open the file in write mode and write the data as JSON\n",
    "    with open(path_to_export, \"w\") as file:\n",
    "        json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a short blog post about a recipe and the inspiration behind it. Do not include a title. Only reveal the dish after the story. Start with a one, two or three paragraph story and then move to the recipe. To re-iterate, do not include a title.\n",
      "\n",
      "Story:\n",
      "\n",
      "The recipe I’m sharing today is an amalgamation of my grandmother's traditional Italian pasta dish and my recent trip to Italy. \n",
      "\n",
      "My grandmother, Nonna Maria, always made the most delicious pasta. We would gather around the table, eagerly awaiting the rich aroma that filled our kitchen every time she prepared her signature dish. The scent would always linger in the air, as if it was a promise of the warmth and love that accompanied each bite. \n",
      "\n",
      "When I travelled to Italy, I was determined to recreate the dish to the best of my abilities. I spent hours exploring the bustling markets, indulging in the local cuisine, and soaking up the vibrant culture. Every meal was an experience, and I was eager to incorporate the flavors and techniques I learned into my recipe.\n",
      "\n",
      "After returning home, I sat down to deconstruct the dish and rebuild it in my kitchen. I started with the pasta, carefully selecting the perfect type of wheat and rolling it out to the perfect thickness. The sauce was a blend of traditional Italian ingredients, infused with my unique twist. The result was a dish that not only brought back cherished memories but also embodied the spirit of my journey through Italy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
