{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_lens.utils as utils\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.loading_from_pretrained import OFFICIAL_MODEL_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = utils.get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt2',\n",
       " 'gpt2-medium',\n",
       " 'gpt2-large',\n",
       " 'gpt2-xl',\n",
       " 'distilgpt2',\n",
       " 'facebook/opt-125m',\n",
       " 'facebook/opt-1.3b',\n",
       " 'facebook/opt-2.7b',\n",
       " 'facebook/opt-6.7b',\n",
       " 'facebook/opt-13b',\n",
       " 'facebook/opt-30b',\n",
       " 'facebook/opt-66b',\n",
       " 'EleutherAI/gpt-neo-125M',\n",
       " 'EleutherAI/gpt-neo-1.3B',\n",
       " 'EleutherAI/gpt-neo-2.7B',\n",
       " 'EleutherAI/gpt-j-6B',\n",
       " 'EleutherAI/gpt-neox-20b',\n",
       " 'stanford-crfm/alias-gpt2-small-x21',\n",
       " 'stanford-crfm/battlestar-gpt2-small-x49',\n",
       " 'stanford-crfm/caprica-gpt2-small-x81',\n",
       " 'stanford-crfm/darkmatter-gpt2-small-x343',\n",
       " 'stanford-crfm/expanse-gpt2-small-x777',\n",
       " 'stanford-crfm/arwen-gpt2-medium-x21',\n",
       " 'stanford-crfm/beren-gpt2-medium-x49',\n",
       " 'stanford-crfm/celebrimbor-gpt2-medium-x81',\n",
       " 'stanford-crfm/durin-gpt2-medium-x343',\n",
       " 'stanford-crfm/eowyn-gpt2-medium-x777',\n",
       " 'EleutherAI/pythia-14m',\n",
       " 'EleutherAI/pythia-31m',\n",
       " 'EleutherAI/pythia-70m',\n",
       " 'EleutherAI/pythia-160m',\n",
       " 'EleutherAI/pythia-410m',\n",
       " 'EleutherAI/pythia-1b',\n",
       " 'EleutherAI/pythia-1.4b',\n",
       " 'EleutherAI/pythia-2.8b',\n",
       " 'EleutherAI/pythia-6.9b',\n",
       " 'EleutherAI/pythia-12b',\n",
       " 'EleutherAI/pythia-70m-deduped',\n",
       " 'EleutherAI/pythia-160m-deduped',\n",
       " 'EleutherAI/pythia-410m-deduped',\n",
       " 'EleutherAI/pythia-1b-deduped',\n",
       " 'EleutherAI/pythia-1.4b-deduped',\n",
       " 'EleutherAI/pythia-2.8b-deduped',\n",
       " 'EleutherAI/pythia-6.9b-deduped',\n",
       " 'EleutherAI/pythia-12b-deduped',\n",
       " 'EleutherAI/pythia-70m-v0',\n",
       " 'EleutherAI/pythia-160m-v0',\n",
       " 'EleutherAI/pythia-410m-v0',\n",
       " 'EleutherAI/pythia-1b-v0',\n",
       " 'EleutherAI/pythia-1.4b-v0',\n",
       " 'EleutherAI/pythia-2.8b-v0',\n",
       " 'EleutherAI/pythia-6.9b-v0',\n",
       " 'EleutherAI/pythia-12b-v0',\n",
       " 'EleutherAI/pythia-70m-deduped-v0',\n",
       " 'EleutherAI/pythia-160m-deduped-v0',\n",
       " 'EleutherAI/pythia-410m-deduped-v0',\n",
       " 'EleutherAI/pythia-1b-deduped-v0',\n",
       " 'EleutherAI/pythia-1.4b-deduped-v0',\n",
       " 'EleutherAI/pythia-2.8b-deduped-v0',\n",
       " 'EleutherAI/pythia-6.9b-deduped-v0',\n",
       " 'EleutherAI/pythia-12b-deduped-v0',\n",
       " 'EleutherAI/pythia-160m-seed1',\n",
       " 'EleutherAI/pythia-160m-seed2',\n",
       " 'EleutherAI/pythia-160m-seed3',\n",
       " 'NeelNanda/SoLU_1L_v9_old',\n",
       " 'NeelNanda/SoLU_2L_v10_old',\n",
       " 'NeelNanda/SoLU_4L_v11_old',\n",
       " 'NeelNanda/SoLU_6L_v13_old',\n",
       " 'NeelNanda/SoLU_8L_v21_old',\n",
       " 'NeelNanda/SoLU_10L_v22_old',\n",
       " 'NeelNanda/SoLU_12L_v23_old',\n",
       " 'NeelNanda/SoLU_1L512W_C4_Code',\n",
       " 'NeelNanda/SoLU_2L512W_C4_Code',\n",
       " 'NeelNanda/SoLU_3L512W_C4_Code',\n",
       " 'NeelNanda/SoLU_4L512W_C4_Code',\n",
       " 'NeelNanda/SoLU_6L768W_C4_Code',\n",
       " 'NeelNanda/SoLU_8L1024W_C4_Code',\n",
       " 'NeelNanda/SoLU_10L1280W_C4_Code',\n",
       " 'NeelNanda/SoLU_12L1536W_C4_Code',\n",
       " 'NeelNanda/GELU_1L512W_C4_Code',\n",
       " 'NeelNanda/GELU_2L512W_C4_Code',\n",
       " 'NeelNanda/GELU_3L512W_C4_Code',\n",
       " 'NeelNanda/GELU_4L512W_C4_Code',\n",
       " 'NeelNanda/Attn_Only_1L512W_C4_Code',\n",
       " 'NeelNanda/Attn_Only_2L512W_C4_Code',\n",
       " 'NeelNanda/Attn_Only_3L512W_C4_Code',\n",
       " 'NeelNanda/Attn_Only_4L512W_C4_Code',\n",
       " 'NeelNanda/Attn-Only-2L512W-Shortformer-6B-big-lr',\n",
       " 'NeelNanda/SoLU_1L512W_Wiki_Finetune',\n",
       " 'NeelNanda/SoLU_4L512W_Wiki_Finetune',\n",
       " 'ArthurConmy/redwood_attn_2l',\n",
       " 'llama-7b-hf',\n",
       " 'llama-13b-hf',\n",
       " 'llama-30b-hf',\n",
       " 'llama-65b-hf',\n",
       " 'meta-llama/Llama-2-7b-hf',\n",
       " 'meta-llama/Llama-2-7b-chat-hf',\n",
       " 'meta-llama/Llama-2-13b-hf',\n",
       " 'meta-llama/Llama-2-13b-chat-hf',\n",
       " 'meta-llama/Llama-2-70b-chat-hf',\n",
       " 'CodeLlama-7b-hf',\n",
       " 'CodeLlama-7b-Python-hf',\n",
       " 'CodeLlama-7b-Instruct-hf',\n",
       " 'meta-llama/Meta-Llama-3-8B',\n",
       " 'meta-llama/Meta-Llama-3-8B-Instruct',\n",
       " 'meta-llama/Meta-Llama-3-70B',\n",
       " 'meta-llama/Meta-Llama-3-70B-Instruct',\n",
       " 'Baidicoot/Othello-GPT-Transformer-Lens',\n",
       " 'bert-base-cased',\n",
       " 'roneneldan/TinyStories-1M',\n",
       " 'roneneldan/TinyStories-3M',\n",
       " 'roneneldan/TinyStories-8M',\n",
       " 'roneneldan/TinyStories-28M',\n",
       " 'roneneldan/TinyStories-33M',\n",
       " 'roneneldan/TinyStories-Instruct-1M',\n",
       " 'roneneldan/TinyStories-Instruct-3M',\n",
       " 'roneneldan/TinyStories-Instruct-8M',\n",
       " 'roneneldan/TinyStories-Instruct-28M',\n",
       " 'roneneldan/TinyStories-Instruct-33M',\n",
       " 'roneneldan/TinyStories-1Layer-21M',\n",
       " 'roneneldan/TinyStories-2Layers-33M',\n",
       " 'roneneldan/TinyStories-Instuct-1Layer-21M',\n",
       " 'roneneldan/TinyStories-Instruct-2Layers-33M',\n",
       " 'stabilityai/stablelm-base-alpha-3b',\n",
       " 'stabilityai/stablelm-base-alpha-7b',\n",
       " 'stabilityai/stablelm-tuned-alpha-3b',\n",
       " 'stabilityai/stablelm-tuned-alpha-7b',\n",
       " 'mistralai/Mistral-7B-v0.1',\n",
       " 'mistralai/Mistral-7B-Instruct-v0.1',\n",
       " 'mistralai/Mixtral-8x7B-v0.1',\n",
       " 'mistralai/Mixtral-8x7B-Instruct-v0.1',\n",
       " 'bigscience/bloom-560m',\n",
       " 'bigscience/bloom-1b1',\n",
       " 'bigscience/bloom-1b7',\n",
       " 'bigscience/bloom-3b',\n",
       " 'bigscience/bloom-7b1',\n",
       " 'bigcode/santacoder',\n",
       " 'Qwen/Qwen-1_8B',\n",
       " 'Qwen/Qwen-7B',\n",
       " 'Qwen/Qwen-14B',\n",
       " 'Qwen/Qwen-1_8B-Chat',\n",
       " 'Qwen/Qwen-7B-Chat',\n",
       " 'Qwen/Qwen-14B-Chat',\n",
       " 'Qwen/Qwen1.5-0.5B',\n",
       " 'Qwen/Qwen1.5-0.5B-Chat',\n",
       " 'Qwen/Qwen1.5-1.8B',\n",
       " 'Qwen/Qwen1.5-1.8B-Chat',\n",
       " 'Qwen/Qwen1.5-4B',\n",
       " 'Qwen/Qwen1.5-4B-Chat',\n",
       " 'Qwen/Qwen1.5-7B',\n",
       " 'Qwen/Qwen1.5-7B-Chat',\n",
       " 'Qwen/Qwen1.5-14B',\n",
       " 'Qwen/Qwen1.5-14B-Chat',\n",
       " 'microsoft/phi-1',\n",
       " 'microsoft/phi-1_5',\n",
       " 'microsoft/phi-2',\n",
       " 'microsoft/Phi-3-mini-4k-instruct',\n",
       " 'google/gemma-2b',\n",
       " 'google/gemma-7b',\n",
       " 'google/gemma-2b-it',\n",
       " 'google/gemma-7b-it',\n",
       " '01-ai/Yi-6B',\n",
       " '01-ai/Yi-34B',\n",
       " '01-ai/Yi-6B-Chat',\n",
       " '01-ai/Yi-34B-Chat',\n",
       " 'google-t5/t5-small',\n",
       " 'google-t5/t5-base',\n",
       " 'google-t5/t5-large',\n",
       " 'ai-forever/mGPT']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OFFICIAL_MODEL_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/SPAR/interp/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce87d8f991464499bd74d2dd686ed6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898304f5cc6c427f94022f396823d8e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6321e86d35c452eb65a0992d8a949d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd325fba40834194ab37cf7a179ad882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750ab3f5b7224b40bcec0f52203dd8de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9c154b0a644b84807bb387e7f52914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ff56f57206491fa7f2d11ca45d4361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-large into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\n",
    "    \"meta-llama/Meta-Llama-3-8B-Instruct\", device=device\n",
    ")\n",
    "# model = HookedTransformer.from_pretrained(\n",
    "#     \"gpt2-large\", device=device\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a004ea90534c4181b83e9a8aff051e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a short blogpost about a recipe and the inspiration behind it.\n",
      "\n",
      "\n",
      "Please note that this is not \n",
      "a recipe competition, but a way to have fun and share with other people, maybe even with famous peop\n",
      "le!\n",
      "\n",
      "\n",
      "This recipe is also available under the main recipe category. If you're interested in creating\n",
      " recipes like this, be sure to check out our blog, \"Cheap and Delicious\" (http://cheapanddelicious.c\n",
      "om).\n",
      "\n",
      "\n",
      "Please note: Please do not include the recipe on the blog. We will not publish it. If you wan\n",
      "t to share it, it's better to use the link below.\n",
      "\n",
      "\n",
      "Quick and Easy Korean Beef Noodle Soup\n",
      "\n",
      "Ingredie\n",
      "nts for 4 servings:\n",
      "\n",
      "\n",
      "1 pound beef (about 4.5 pounds)\n",
      "\n",
      "1 large onion, diced\n",
      "\n",
      "2 tablespoons butter\n",
      "\n",
      "1\n",
      " tablespoon fish sauce\n",
      "\n",
      "1 large red pepper, diced\n",
      "\n",
      "2 cloves garlic, minced\n",
      "\n",
      "1/2 cup vegetable broth\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(\n",
    "    \"Write a short blogpost about a recipe and the inspiration behind it.\\n\\n\",\n",
    "    max_new_tokens=200,\n",
    "    temperature=0.7,\n",
    "    prepend_bos=False,\n",
    ")\n",
    "\n",
    "print(\"\\n\".join(output[i * 100 : (i + 1) * 100] for i in range(len(output) // 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
