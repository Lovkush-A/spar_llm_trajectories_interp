{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taker import Model\n",
    "from datetime import datetime\n",
    "import json\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, \"w\")\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"microsoft/phi-3-mini-4k-instruct\"\n",
    "model_name = \"google/gemma-2-2b-it\"\n",
    "m = Model(model_name, dtype=\"int4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.show_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idlist = m.get_ids(\".\\n\\n\").squeeze().tolist()\n",
    "print(idlist)\n",
    "print(m.tokenizer.convert_ids_to_tokens(idlist))\n",
    "\n",
    "idlist = m.get_ids(\"Sunday dinners.\\n\\n\").squeeze().tolist()\n",
    "print(idlist)\n",
    "print(m.tokenizer.convert_ids_to_tokens(idlist))\n",
    "\n",
    "idlist = m.get_ids(\".\" * 16 * 5).squeeze().tolist()\n",
    "print(idlist)\n",
    "print(m.tokenizer.convert_ids_to_tokens(idlist))\n",
    "\n",
    "idlist = m.get_ids(\".\" * (16 * 5 + 1)).squeeze().tolist()\n",
    "print(idlist)\n",
    "print(m.tokenizer.convert_ids_to_tokens(idlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.generate(\"Sunday dinners.\\n\\n\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Write a short blog post about a recipe and the inspiration behind it.\n",
    " Do not include a title.\n",
    " Only reveal the dish after the story.\n",
    " Start with short story and then move to the recipe.\n",
    " To re-iterate, do not include a title.\"\"\"\n",
    "\n",
    "\n",
    "story = \"\"\"\n",
    "\\n Once upon a time, in a quaint little village nestled between rolling hills and verdant fields, there lived an elderly woman named Agnes. Agnes was known for her warm smile and her legendary Sunday dinners that brought the entire neighborhood together. Her recipes were family heirlooms, passed down through generations, with each family adding their own touch to the final dish.\n",
    "\n",
    "One crisp autumn evening, Agnes was reminiscing about her childhood, and how her grandmother used to gather everyone around the dinner table, sharing stories and laughter. These were the moments that shaped her, the memories that she passed on to her own children and grandchildren.\n",
    "\n",
    "Inspired by her grandmother's legacy, Agnes decided to create a new dish that would encapsulate the essence of those cherished gatherings. She wanted something that was comforting and nourishing, a dish that could be prepared with love and shared with others. After days of experimentation, she finally created a recipe that she believed truly captured the spirit of her family's Sunday dinners.\\n\\n\"\"\"\n",
    "\n",
    "prompt_original = prompt + story\n",
    "print(prompt_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens_to_transfer = 2\n",
    "\n",
    "idlist_original = m.get_ids(prompt_original).squeeze().tolist()\n",
    "tokens_original = m.tokenizer.convert_ids_to_tokens(idlist_original)\n",
    "n_tokens_original = len(tokens_original)\n",
    "\n",
    "# prompt is just string of dots.\n",
    "prompt_new = \".\" * 16 * n_tokens_to_transfer\n",
    "\n",
    "# prefix = \"\"\n",
    "# tokens_to_transfer = tokens_original[-n_tokens_to_transfer:]\n",
    "# string_to_transfer = m.tokenizer.convert_tokens_to_string(tokens_to_transfer)\n",
    "# prompt_new = prefix + string_to_transfer\n",
    "print(f\"{prompt_new=}\")\n",
    "\n",
    "idlist_new = m.get_ids(prompt_new).squeeze().tolist()\n",
    "tokens_new = m.tokenizer.convert_ids_to_tokens(idlist_new)\n",
    "n_tokens_new = len(tokens_new)\n",
    "\n",
    "token_index_map = {\n",
    "    n_tokens_original\n",
    "    - n_tokens_to_transfer\n",
    "    + i: n_tokens_new\n",
    "    - n_tokens_to_transfer\n",
    "    + i\n",
    "    for i in range(n_tokens_to_transfer)\n",
    "}\n",
    "\n",
    "# # do sense check\n",
    "# for index_original, index_new in token_index_map.items():\n",
    "#     assert tokens_original[index_original] == tokens_new[index_new]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESET HOOKS BEFORE TRANSPLANTING NEXT SET OF ACTIVATIONS\n",
    "for h in m.hooks.neuron_replace.values():\n",
    "    h.reset()\n",
    "\n",
    "print(m.hooks.neuron_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_original = m.get_midlayer_activations(prompt_original)\n",
    "\n",
    "for original_index, new_index in token_index_map.items():\n",
    "    for layer_type in [\"mlp\", \"attn\"]:\n",
    "        # for layer_type in [\"attn\"]:\n",
    "        for layer_number in range(26):\n",
    "            hook = m.hooks.neuron_replace[f\"layer_{layer_number}_{layer_type}_pre_out\"]\n",
    "            hook.add_token(\n",
    "                new_index,\n",
    "                activations_original[layer_type][0, layer_number, original_index],\n",
    "            )\n",
    "\n",
    "# for original_index, new_index in token_index_map.items():\n",
    "#     for name, hook in m.hooks.neuron_replace.items():\n",
    "#         # name is of the form \"layer_{layer_number}_{layer_type}_pre_out\"\n",
    "#         _, layer_number, layer_type, _, _ = name.split(\"_\")\n",
    "#         layer_number = int(layer_number)\n",
    "#         hook.add_token(new_index, activations_original[layer_type][0, layer_number, original_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "current_time = \"2024-08-20_08-26-41\"\n",
    "filename = f\"../results/{current_time}_agnes_multi_token_transfer_LA_tests.jsonl\"\n",
    "\n",
    "if not exists(filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_new_tokens = 200\n",
    "temperature = 0.01\n",
    "\n",
    "# test on single output\n",
    "output = m.generate(prompt_new, max_new_tokens, temperature=temperature)\n",
    "print(output[1])\n",
    "\n",
    "# with HiddenPrints():\n",
    "#     for i in range(20):\n",
    "#         output = m.generate(prompt_new, max_new_tokens, temperature=temperature)\n",
    "\n",
    "#         data = {\n",
    "#             \"temperature\": temperature,\n",
    "#             \"max_new_tokens\": max_new_tokens,\n",
    "#             \"model\": model_name,\n",
    "#             \"transplant_layers\": (0, 25),\n",
    "#             \"transferred_token_num\": n_tokens_to_transfer,\n",
    "#             \"orig_prompt\": prompt_original,\n",
    "#             \"transplant_prompt\": prompt_new,\n",
    "#             \"output\": output[1],\n",
    "#             \"other_info\": \"try-different-transfer-layers-with-gemma\",\n",
    "#         }\n",
    "\n",
    "#         with open(filename, \"a\") as file:\n",
    "#             file.write(json.dumps(data) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_layers_transferred in range(1, 26, 2):\n",
    "    # RESET HOOKS BEFORE TRANSPLANTING NEXT SET OF ACTIVATIONS\n",
    "    for h in m.hooks.neuron_replace.values():\n",
    "        h.reset()\n",
    "\n",
    "    activations_original = m.get_midlayer_activations(prompt_original)\n",
    "\n",
    "    for original_index, new_index in token_index_map.items():\n",
    "        for layer_type in [\"mlp\", \"attn\"]:\n",
    "            # for layer_type in [\"attn\"]:\n",
    "            for layer_number in range(n_layers_transferred):\n",
    "                hook = m.hooks.neuron_replace[\n",
    "                    f\"layer_{layer_number}_{layer_type}_pre_out\"\n",
    "                ]\n",
    "                hook.add_token(\n",
    "                    new_index,\n",
    "                    activations_original[layer_type][0, layer_number, original_index],\n",
    "                )\n",
    "\n",
    "    max_new_tokens = 100\n",
    "    temperature = 0.01\n",
    "\n",
    "    with HiddenPrints():\n",
    "        for i in range(3):\n",
    "            output = m.generate(prompt_new, max_new_tokens, temperature=temperature)\n",
    "\n",
    "            data = {\n",
    "                \"temperature\": temperature,\n",
    "                \"max_new_tokens\": max_new_tokens,\n",
    "                \"model\": model_name,\n",
    "                \"transplant_layers\": (0, n_layers_transferred - 1),\n",
    "                \"transferred_token_num\": n_tokens_to_transfer,\n",
    "                \"orig_prompt\": prompt_original,\n",
    "                \"transplant_prompt\": prompt_new,\n",
    "                \"output\": output[1],\n",
    "                \"other_info\": f\"transfer-first-{n_layers_transferred}-layers--prompt-new-is-just-dots\",\n",
    "            }\n",
    "\n",
    "            with open(filename, \"a\") as file:\n",
    "                file.write(json.dumps(data) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
