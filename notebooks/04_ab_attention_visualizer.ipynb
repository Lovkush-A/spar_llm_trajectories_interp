{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install taker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from transformer_lens import HookedTransformer\n",
    "import circuitsvis as cv\n",
    "import numpy as np\n",
    "import torch\n",
    "from taker import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = utils.get_device()\n",
    "print(device)\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-large\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = \"\"\"\n",
    "# Please generate an inspirational story followed by recipe instructions.\\n\n",
    "# In a small village, Eliza was known for her magical garden. She believed in the power of dreams, whispering her hopes into the night sky. One spring, a storm ravaged the village, destroying the crops. Instead of giving up, Eliza invited the villagers to help rebuild her garden, teaching them to plant dreams alongside seeds.\n",
    "\n",
    "# The garden flourished, and the community grew closer, sharing their harvests and ensuring no one went hungry. Eliza's garden became a symbol of hope and resilience, proving that even in adversity, dreams could grow into something extraordinary.\n",
    "\n",
    "# Recipe: Garden Vegetable Pasta\n",
    "# Ingredients:\n",
    "\n",
    "# 200g pasta\n",
    "# 2 tbsp olive oil\n",
    "# 1 onion, chopped\n",
    "# 2 garlic cloves, minced\n",
    "# 1 red bell pepper, chopped\n",
    "# 1 yellow bell pepper, chopped\n",
    "# 1 zucchini, sliced\n",
    "# 1 cup cherry tomatoes, halved\n",
    "# 1 cup spinach leaves\n",
    "# 1/4 cup fresh basil, chopped\n",
    "# 1/4 cup grated Parmesan cheese\n",
    "# Salt and pepper to taste\n",
    "# Instructions:\n",
    "\n",
    "# Cook the Pasta: Boil water, add pasta, cook until al dente. Drain and set aside.\n",
    "# Sauté the Vegetables: Heat olive oil in a skillet. Add onion and garlic, sauté for 3-4 minutes. Add bell peppers, cook 5 minutes. Add zucchini, cook 3-4 minutes.\n",
    "# Combine Ingredients: Add cherry tomatoes, cook 3 minutes. Stir in spinach, cook until wilted.\n",
    "# Mix with Pasta: Add pasta to skillet, toss with vegetables. Season with salt and pepper.\n",
    "# Serve: Stir in basil, sprinkle with Parmesan.\n",
    "# \"\"\"\n",
    "\n",
    "output = \"\"\"\n",
    "Please generate an inspirational story followed by recipe instructions.\\n\n",
    "A tiny seed dreamed of reaching the sky. With patience and care, it grew into a magnificent tree, providing shade and shelter, showing that even the smallest dreams can grow into something great.\n",
    "\n",
    "Recipe: Simple Avocado Toast\n",
    "Ingredients:\n",
    "\n",
    "1 ripe avocado\n",
    "2 slices of bread\n",
    "Salt and pepper\n",
    "Lemon juice\n",
    "Instructions:\n",
    "\n",
    "Toast the bread.\n",
    "Mash the avocado with salt, pepper, and a splash of lemon juice.\n",
    "Spread the mixture on the toast. Enjoy!\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tokens = model.to_tokens(output, prepend_bos=False)\n",
    "model_logits, cache = model.run_with_cache(model_tokens, remove_batch_dim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layer = torch.stack each layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.W_Q.shape)\n",
    "nhead = model.W_Q.shape[1]\n",
    "nlayer = model.W_Q.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(nlayer): #get attention patterns over each head and over each layer \n",
    "    if i == 0:\n",
    "        head_attention_pattern = cache[\"pattern\", i, \"attn\"].clone()\n",
    "        layer_attention_pattern = torch.sum(cache[\"pattern\", i, \"attn\"].clone(),axis=0).unsqueeze(0)\n",
    "        print(head_attention_pattern.shape)\n",
    "        print(layer_attention_pattern.shape)\n",
    "    else:\n",
    "        head_attention_pattern += cache[\"pattern\", i, \"attn\"] # [nheads x src_len x dest_len]\n",
    "        layer_attention_pattern = torch.cat((layer_attention_pattern, torch.sum(cache[\"pattern\", i, \"attn\"].clone(),axis=0).unsqueeze(0)), axis=0) # [nlayers x src_len x dest_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_layer_attention_pattern(savefile=False):\n",
    "    print(\"HEAD = LAYER\")\n",
    "    attention_pattern = layer_attention_pattern[:, 1:, 1:] # remove first token from src and dest\n",
    "    attn_max_val = torch.max(attention_pattern)\n",
    "    attn_min_val = torch.min(attention_pattern)\n",
    "    \n",
    "    model_str_tokens = model.to_str_tokens(output, prepend_bos=False)\n",
    "    model_str_tokens = model_str_tokens[1:]\n",
    "    print(attention_pattern.shape)\n",
    "    attention_pattern=attention_pattern[0:18,:,:]\n",
    "    \n",
    "    display(cv.attention.attention_heads(\n",
    "        tokens=model_str_tokens,\n",
    "        attention=attention_pattern,\n",
    "        max_value=attn_max_val,\n",
    "        min_value=attn_min_val,\n",
    "    )\n",
    "    )\n",
    "    \n",
    "    if savefile==True:\n",
    "        html =  cv.attention.attention_heads(\n",
    "        tokens=model_str_tokens,\n",
    "        attention=attention_pattern,\n",
    "        max_value=attn_max_val,\n",
    "        min_value=attn_min_val,\n",
    "        )\n",
    "        with open(\"attn_graphs/layer_attn_patterns_prompt_small_0-17.html\", \"w\") as f:\n",
    "            f.write(str(html))\n",
    "def generate_head_attention_pattern(savefile=False):\n",
    "    attention_pattern = head_attention_pattern[:, 1:, 1:] # remove first token from src and dest\n",
    "    attn_max_val = torch.max(attention_pattern)\n",
    "    attn_min_val = torch.min(attention_pattern)\n",
    "    print(attention_pattern.shape)\n",
    "\n",
    "    model_str_tokens = model.to_str_tokens(output, prepend_bos=False)\n",
    "    model_str_tokens = model_str_tokens[1:]\n",
    "    # display(cv.attention.attention_heads(\n",
    "    #     tokens=model_str_tokens,\n",
    "    #     attention=attention_pattern,\n",
    "    #     max_value=attn_max_val,\n",
    "    #     min_value=attn_min_val,\n",
    "    # )\n",
    "    # )\n",
    "    if savefile==True:\n",
    "        html =  cv.attention.attention_heads(\n",
    "        tokens=model_str_tokens,\n",
    "        attention=attention_pattern,\n",
    "        max_value=attn_max_val,\n",
    "        min_value=attn_min_val,\n",
    "        )\n",
    "        with open(\"attn_graphs/head_attn_patterns.html\", \"w\") as f:\n",
    "            f.write(str(html))\n",
    "def generate_full_attention_pattern(savefile=False):\n",
    "    attention_pattern = head_attention_pattern[:, 1:, 1:] # remove first token from src and dest\n",
    "    attention_pattern = torch.sum(attention_pattern,axis=0)\n",
    "    attn_max_val = torch.max(attention_pattern)\n",
    "    attn_min_val = torch.min(attention_pattern)\n",
    "    print(attention_pattern.shape)\n",
    "\n",
    "    model_str_tokens = model.to_str_tokens(output, prepend_bos=False)\n",
    "    model_str_tokens = model_str_tokens[1:] \n",
    "    \n",
    "    display(cv.attention.attention_pattern(\n",
    "        tokens=model_str_tokens,\n",
    "        attention=attention_pattern,\n",
    "        max_value=attn_max_val,\n",
    "        min_value=attn_min_val,\n",
    "    )\n",
    "    )\n",
    "    if savefile==True:\n",
    "        html =  cv.attention.attention_pattern(\n",
    "        tokens=model_str_tokens,\n",
    "        attention=attention_pattern,\n",
    "        max_value=attn_max_val,\n",
    "        min_value=attn_min_val,\n",
    "        )\n",
    "        with open(\"attn_graphs/all_attn_patterns_prompt.html\", \"w\") as f:\n",
    "            f.write(str(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_layer_attention_pattern(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
