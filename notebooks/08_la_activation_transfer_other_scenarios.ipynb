{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferring activations from end of prompt and generating text\n",
    "\n",
    "Trying on other scenarios.\n",
    "\n",
    "Contents:\n",
    "- Create helper function\n",
    "- Load model\n",
    "- Create prompts\n",
    "- Transfer activations\n",
    "- Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/SPAR/interp-la/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from taker import Model\n",
    "from datetime import datetime\n",
    "import json\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, \"w\")\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model 'google/gemma-2-2b-it' with int4:\n",
      "- Added 416 hooks across 26 layers\n"
     ]
    }
   ],
   "source": [
    "# model_name = \"microsoft/phi-3-mini-4k-instruct\"\n",
    "model_name = \"google/gemma-2-2b-it\"\n",
    "m = Model(model_name, dtype=\"int4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - n_layers : 26\n",
      " - d_model  : 2304\n",
      " - n_heads  : 8\n",
      " - d_head   : 256\n",
      " - d_mlp    : 9216\n"
     ]
    }
   ],
   "source": [
    "m.show_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 235265, 109]\n",
      "['<bos>', '.', '\\n\\n']\n",
      "[2, 20742, 90641, 235265, 109]\n",
      "['<bos>', 'Sunday', '▁dinners', '.', '\\n\\n']\n",
      "[2, 5519, 5519, 5519, 5519, 5519]\n",
      "['<bos>', '................', '................', '................', '................', '................']\n",
      "[2, 5519, 5519, 5519, 5519, 2779, 25984]\n",
      "['<bos>', '................', '................', '................', '................', '........', '.........']\n",
      "[2, 177176, 177176, 177176, 177176, 177176]\n",
      "['<bos>', '@@@@@@@@', '@@@@@@@@', '@@@@@@@@', '@@@@@@@@', '@@@@@@@@']\n",
      "[2, 177176, 177176, 177176, 177176, 177176, 235348]\n",
      "['<bos>', '@@@@@@@@', '@@@@@@@@', '@@@@@@@@', '@@@@@@@@', '@@@@@@@@', '@']\n",
      "[2, 3755, 3755, 3755, 3755, 3755]\n",
      "['<bos>', '----------------', '----------------', '----------------', '----------------', '----------------']\n",
      "[2, 3755, 3755, 3755, 3755, 3755, 235290]\n",
      "['<bos>', '----------------', '----------------', '----------------', '----------------', '----------------', '-']\n"
     ]
    }
   ],
   "source": [
    "idlist = m.get_ids(\".\\n\\n\").squeeze().tolist()\n",
    "print(idlist)\n",
    "print(m.tokenizer.convert_ids_to_tokens(idlist))\n",
    "\n",
    "idlist = m.get_ids(\"Sunday dinners.\\n\\n\").squeeze().tolist()\n",
    "print(idlist)\n",
    "print(m.tokenizer.convert_ids_to_tokens(idlist))\n",
    "\n",
    "# # for phi3\n",
    "# idlist = m.get_ids(\".\" * 16 * 5).squeeze().tolist()\n",
    "# print(idlist)\n",
    "# print(m.tokenizer.convert_ids_to_tokens(idlist))\n",
    "\n",
    "# idlist = m.get_ids(\".\" * (16 * 5 + 1)).squeeze().tolist()\n",
    "# print(idlist)\n",
    "# print(m.tokenizer.convert_ids_to_tokens(idlist))\n",
    "\n",
    "# for gemma\n",
    "idlist = m.get_ids(\".\" * 16 * 5).squeeze().tolist()\n",
    "print(idlist)\n",
    "print(m.tokenizer.convert_ids_to_tokens(idlist))\n",
    "\n",
    "idlist = m.get_ids(\".\" * (16 * 5 + 1)).squeeze().tolist()\n",
    "print(idlist)\n",
    "print(m.tokenizer.convert_ids_to_tokens(idlist))\n",
    "\n",
    "idlist = m.get_ids(\"@\" * 8 * 5).squeeze().tolist()\n",
    "print(idlist)\n",
    "print(m.tokenizer.convert_ids_to_tokens(idlist))\n",
    "\n",
    "idlist = m.get_ids(\"@\" * (8 * 5 + 1)).squeeze().tolist()\n",
    "print(idlist)\n",
    "print(m.tokenizer.convert_ids_to_tokens(idlist))\n",
    "\n",
    "idlist = m.get_ids(\"-\" * 16 * 5).squeeze().tolist()\n",
    "print(idlist)\n",
    "print(m.tokenizer.convert_ids_to_tokens(idlist))\n",
    "\n",
    "idlist = m.get_ids(\"-\" * (16 * 5 + 1)).squeeze().tolist()\n",
    "print(idlist)\n",
    "print(m.tokenizer.convert_ids_to_tokens(idlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"The sport of axe-throwing involves players aiming to throw axes at a designated target board. The game is a blend of target practice, precision and athleticism. It requires the use of specialized axes specifically designed for the sport. These axes are typically lighter and more aerodynamic than traditional axes. \\nIn recent years, axe-throwing has become increasingly popular, particularly among groups of friends or individuals looking for a fun activity. It's a social activity, providing opportunities for friendly competition and camaraderie.\\n\\nContactless payments are revolutionizing the way we transact. They offer convenience, security, and speed.  Contactless payments can be made through various methods: NFC chip technology, Bluetooth, QR codes, or even smart cards.  They are being used by businesses, restaurants, and individuals.\\nThis technology has become a global phenomenon, with many countries adopting contactless payments. It has significantly reduced the need for physical cash and changed the way we interact with our financial systems.\\n\\n\\n \\n\"\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"Tell me about {topic1} in 150 words and then tell me about {topic2} in another 150 words. Only do that. Make sure you don't add any headings or comments.\\n\\n\"\n",
    "# prompt_template = \"Tell me about {topic1} in 150 words and then tell me about {topic2} in another 150 words and then tell me about {topic3} in another 150 words. Only do that. Make sure you don't add any headings or comments.\\n\\n\"\n",
    "topic1 = \"axe-throwing\"\n",
    "topic2 = \"contactless payments\"\n",
    "# topic3 = \"the history of paper\"\n",
    "prompt = prompt_template.format(topic1=topic1, topic2=topic2)\n",
    "# prompt = prompt_template.format(topic1=topic1, topic2=topic2, topic3=topic3)\n",
    "output = m.generate(prompt, 400)\n",
    "print(repr(output[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me about axe-throwing in 150 words and then tell me about contactless payments in another 150 words. Only do that. Make sure you don't add any headings or comments.\n",
      "\n",
      "The sport of axe-throwing involves players aiming to throw axes at a designated target board. The game is a blend of target practice, precision and athleticism. It requires the use of specialized axes specifically designed for the sport. These axes are typically lighter and more aerodynamic than traditional axes. \n",
      "In recent years, axe-throwing has become increasingly popular, particularly among groups of friends or individuals looking for a fun activity. It's a social activity, providing opportunities for friendly competition and camaraderie.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = \"The sport of axe-throwing involves players aiming to throw axes at a designated target board. The game is a blend of target practice, precision and athleticism. It requires the use of specialized axes specifically designed for the sport. These axes are typically lighter and more aerodynamic than traditional axes. \\nIn recent years, axe-throwing has become increasingly popular, particularly among groups of friends or individuals looking for a fun activity. It's a social activity, providing opportunities for friendly competition and camaraderie.\\n\\n\"\n",
    "prompt_original = prompt + start\n",
    "print(prompt_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_prompt_from_end_tokens(m, prompt_original, n_tokens_to_transfer, prefix):\n",
    "    idlist_original = m.get_ids(prompt_original).squeeze().tolist()\n",
    "    tokens_original = m.tokenizer.convert_ids_to_tokens(idlist_original)\n",
    "    n_tokens_original = len(tokens_original)\n",
    "\n",
    "    tokens_to_transfer = tokens_original[-n_tokens_to_transfer:]\n",
    "    string_to_transfer = m.tokenizer.convert_tokens_to_string(tokens_to_transfer)\n",
    "    prompt_new = prefix + string_to_transfer\n",
    "\n",
    "    idlist_new = m.get_ids(prompt_new).squeeze().tolist()\n",
    "    tokens_new = m.tokenizer.convert_ids_to_tokens(idlist_new)\n",
    "    n_tokens_new = len(tokens_new)\n",
    "\n",
    "    token_index_map = {\n",
    "        n_tokens_original\n",
    "        - n_tokens_to_transfer\n",
    "        + i: n_tokens_new\n",
    "        - n_tokens_to_transfer\n",
    "        + i\n",
    "        for i in range(n_tokens_to_transfer)\n",
    "    }\n",
    "\n",
    "    return prompt_new, token_index_map, tokens_original, tokens_new\n",
    "\n",
    "\n",
    "def create_new_prompt_by_repeating_dummy_string(\n",
    "    m, prompt_original, dummy_string, n_tokens_to_transfer, prefix\n",
    "):\n",
    "    idlist_original = m.get_ids(prompt_original).squeeze().tolist()\n",
    "    tokens_original = m.tokenizer.convert_ids_to_tokens(idlist_original)\n",
    "    n_tokens_original = len(tokens_original)\n",
    "\n",
    "    prompt_new = prefix + dummy_string * n_tokens_to_transfer\n",
    "\n",
    "    idlist_new = m.get_ids(prompt_new).squeeze().tolist()\n",
    "    tokens_new = m.tokenizer.convert_ids_to_tokens(idlist_new)\n",
    "    n_tokens_new = len(tokens_new)\n",
    "\n",
    "    token_index_map = {\n",
    "        n_tokens_original\n",
    "        - n_tokens_to_transfer\n",
    "        + i: n_tokens_new\n",
    "        - n_tokens_to_transfer\n",
    "        + i\n",
    "        for i in range(n_tokens_to_transfer)\n",
    "    }\n",
    "\n",
    "    return prompt_new, token_index_map, tokens_original, tokens_new\n",
    "\n",
    "\n",
    "def create_new_prompt_by_transferring_all_of_one_token_type(\n",
    "    m, prompt_original, token_to_transfer, dummy_string\n",
    "):\n",
    "    idlist_original = m.get_ids(prompt_original).squeeze().tolist()\n",
    "    tokens_original = m.tokenizer.convert_ids_to_tokens(idlist_original)\n",
    "\n",
    "    prompt_new = \"\"\n",
    "    n_tokens_to_transfer = 0\n",
    "    # this maps the index of token in tokens_original to the index of token in tokens_new\n",
    "    token_index_map = {}\n",
    "\n",
    "    for i, token in enumerate(tokens_original):\n",
    "        if token == token_to_transfer:\n",
    "            prompt_new += dummy_string\n",
    "            n_tokens_to_transfer += 1\n",
    "            token_index_map[i] = n_tokens_to_transfer\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    idlist_new = m.get_ids(prompt_new).squeeze().tolist()\n",
    "    tokens_new = m.tokenizer.convert_ids_to_tokens(idlist_new)\n",
    "\n",
    "    return prompt_new, token_index_map, tokens_original, tokens_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_new='................'\n",
      "tokens_new=['<bos>', '................']\n",
      "\n",
      "{144: 1}\n",
      "\n",
      "'\\n\\n' '................'\n"
     ]
    }
   ],
   "source": [
    "n_tokens_to_transfer = 1\n",
    "\n",
    "# prompt_new, token_index_map, tokens_original, tokens_new = (\n",
    "#     create_new_prompt_from_end_tokens(\n",
    "#         m=m, prompt_original=prompt_original, n_tokens_to_transfer=n_tokens_to_transfer, prefix=\"\"\n",
    "#     )\n",
    "# )\n",
    "\n",
    "prompt_new, token_index_map, tokens_original, tokens_new = (\n",
    "    create_new_prompt_by_repeating_dummy_string(\n",
    "        m=m,\n",
    "        prompt_original=prompt_original,\n",
    "        dummy_string=\".\" * 16,\n",
    "        n_tokens_to_transfer=n_tokens_to_transfer,\n",
    "        prefix=\"\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# prompt_new, token_index_map, tokens_original, tokens_new = create_new_prompt_by_transferring_all_of_one_token_type(\n",
    "#     m=m, prompt_original=prompt_original, token_to_transfer=\"\\n\\n\", dummy_string=\"@\"*8)\n",
    "\n",
    "# do sense check\n",
    "print(f\"{prompt_new=}\")\n",
    "print(f\"{tokens_new=}\")\n",
    "print()\n",
    "print(token_index_map)\n",
    "print()\n",
    "for index_original, index_new in token_index_map.items():\n",
    "    print(repr(tokens_original[index_original]), repr(tokens_new[index_new]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_0_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_0_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_1_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_1_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_2_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_2_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_3_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_3_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_4_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_4_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_5_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_5_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_6_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_6_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_7_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_7_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_8_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_8_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_9_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_9_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_10_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_10_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_11_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_11_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_12_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_12_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_13_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_13_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_14_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_14_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_15_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_15_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_16_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_16_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_17_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_17_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_18_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_18_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_19_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_19_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_20_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_20_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_21_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_21_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_22_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_22_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_23_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_23_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_24_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_24_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_25_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      "), 'layer_25_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict()\n",
      ")}\n"
     ]
    }
   ],
   "source": [
    "# RESET HOOKS BEFORE TRANSPLANTING NEXT SET OF ACTIVATIONS\n",
    "for h in m.hooks.neuron_replace.values():\n",
    "    h.reset()\n",
    "\n",
    "print(m.hooks.neuron_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_0_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_0_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_1_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_1_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_2_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_2_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_3_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_3_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_4_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_4_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_5_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_5_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_6_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_6_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_7_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_7_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_8_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_8_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_9_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_9_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_10_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_10_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_11_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_11_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_12_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_12_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_13_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_13_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_14_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_14_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_15_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_15_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_16_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_16_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_17_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_17_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_18_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_18_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_19_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_19_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_20_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_20_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_21_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_21_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_22_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_22_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_23_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_23_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_24_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_24_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      "), 'layer_25_attn_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 8x256 (cuda:0)])\n",
      "), 'layer_25_mlp_pre_out': NeuronReplace(\n",
      "  (param): ParameterDict(  (1): Parameter containing: [torch.cuda.HalfTensor of size 9216 (cuda:0)])\n",
      ")}\n"
     ]
    }
   ],
   "source": [
    "activations_original = m.get_midlayer_activations(prompt_original)\n",
    "\n",
    "for original_index, new_index in token_index_map.items():\n",
    "    for layer_type in [\"mlp\", \"attn\"]:\n",
    "        # for layer_type in [\"attn\"]:\n",
    "        for layer_number in range(m.cfg.n_layers):\n",
    "            hook = m.hooks.neuron_replace[f\"layer_{layer_number}_{layer_type}_pre_out\"]\n",
    "            hook.add_token(\n",
    "                new_index,\n",
    "                activations_original[layer_type][0, layer_number, original_index],\n",
    "            )\n",
    "\n",
    "print(m.hooks.neuron_replace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "current_time = \"2024-08-22_08-26-53\"\n",
    "filename = f\"../results/{current_time}_LA_activation_transfer_different_scenarios.jsonl\"\n",
    "\n",
    "if not exists(filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_new_tokens = 150\n",
    "temperature = 0.2\n",
    "\n",
    "# test on single output\n",
    "# output = m.generate(prompt_new, max_new_tokens, temperature=temperature)\n",
    "# print(repr(output[1]))\n",
    "\n",
    "with HiddenPrints():\n",
    "    for i in range(3):\n",
    "        output = m.generate(prompt_new, max_new_tokens, temperature=temperature)\n",
    "\n",
    "        data = {\n",
    "            \"temperature\": temperature,\n",
    "            \"max_new_tokens\": max_new_tokens,\n",
    "            \"model\": model_name,\n",
    "            \"transplant_layers\": (0, m.cfg.n_layers),\n",
    "            \"transferred_token_num\": n_tokens_to_transfer,\n",
    "            \"orig_prompt\": prompt_original,\n",
    "            \"transplant_prompt\": prompt_new,\n",
    "            \"other_info\": f\"gemma-{topic1}-{topic2}-try-new-prompt-as-dots-again\",\n",
    "            \"output\": output[1],\n",
    "        }\n",
    "\n",
    "        with open(filename, \"a\") as file:\n",
    "            file.write(json.dumps(data) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
